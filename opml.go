/*
 * Copyright 2014 Brett Slatkin
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package main

import (
	"log"
	"net/http"
	"net/url"
	"sort"
	"strings"
	"text/template"
)

var (
	opmlTemplate = template.Must(template.New("opml").Parse(`<?xml version="1.0" encoding="utf-8"?>
<opml version="1.1">
    <!-- Generated by tweeps2opml -->
    <head>
        <title>Twitter Friends</title>
    </head>
    <body>
        <outline text="Twitter Friends" title="Twitter Friends">
        {{range .}}{{if .Feed.Url}}
	        <outline text="{{.ScreenName}}{{if .Feed.Title}} - {{.Feed.Title | html}}{{end}}" title="{{.ScreenName}}{{if .Feed.Title}} - {{.Feed.Title | html}}{{end}}" type="rss" xmlUrl="{{.Feed.Url | html}}" />
	    {{end}}{{end}}
        </outline>
    </body>
</opml>
`))
)

type Work struct {
	Friend
	Feed Feed
	Done chan *Work
}

func doWork(work *Work) {
	defer func() {
		work.Done <- work
	}()

	log.Printf("Considering %s = %s", work.ScreenName, work.ProfileUrl)

	parsed, err := url.Parse(work.ProfileUrl)
	if err != nil {
		log.Printf("Could not parse url=%s err=%s", work.ProfileUrl, err)
		return
	}

	feeds, err := Discover(parsed)
	if err != nil {
		log.Printf("Could not discover url=%s err=%s", work.ProfileUrl, err)
		return
	}

	work.Feed = GetPrimaryFeed(feeds)
	if work.Feed.Url != "" {
		log.Printf("Discovered %s -> %s", work.ScreenName, work.Feed.Url)
	}
}

func discoverParallel(out chan<- *Work, friends []Friend) {
	defer close(out)

	input := make(chan *Work, len(friends))
	defer close(input)

	// Limit the goroutines to N fetches in parallel
	for i := 0; i < 50; i++ {
		go func() {
			for work := range input {
				doWork(work)
			}
		}()
	}

	queued := make([]*Work, 0, len(friends))
	for _, friend := range friends {
		work := &Work{
			Friend: friend,
			Done:   make(chan *Work),
		}
		queued = append(queued, work)
		input <- work
	}

	for _, work := range queued {
		out <- <-work.Done
	}
}

type FriendList []Friend

func (fl FriendList) Len() int {
	return len(fl)
}

func (fl FriendList) Less(i, j int) bool {
	return fl[i].ScreenName < fl[j].ScreenName
}

func (fl FriendList) Swap(i, j int) {
	fl[i], fl[j] = fl[j], fl[i]
}

func downloadHandler(w http.ResponseWriter, r *http.Request) {
	if err := r.ParseForm(); err != nil {
		log.Printf("Could not parse friend list: %s", err)
		http.Error(w, "Could not parse friend list", http.StatusBadRequest)
		return
	}

	friends := make([]Friend, 0, len(r.PostForm))
	for key, values := range r.PostForm {
		if len(values) == 1 {
			friends = append(friends, Friend{
				ScreenName: strings.ToLower(key),
				ProfileUrl: values[0],
			})
		}
	}
	sort.Sort(FriendList(friends))

	out := make(chan *Work, len(r.PostForm))
	go discoverParallel(out, friends)

	w.Header().Set("Content-Disposition", "attachment; filename=twitter_friends.xml")
	w.Header().Set("Content-Type", "text/xml")
	opmlTemplate.Execute(w, out)
}
